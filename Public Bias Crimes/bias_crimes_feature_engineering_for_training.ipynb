{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d783f6",
   "metadata": {},
   "source": [
    "The following packages/modules are used:\n",
    "- pandas\n",
    "- numpy\n",
    "- NLTLK\n",
    "- scikit-learn\n",
    "- scipy\n",
    "- joblib\n",
    "\n",
    "We also use functions from the NLP_Preprocessing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d8ca0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Manipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#NLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#NLP Preprocessing Functions\n",
    "from NLP_PreProcessing import removeStopWords, removeFeatures, lemmatize\n",
    "\n",
    "#Model Creation \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ed857",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d098a",
   "metadata": {},
   "source": [
    "A dummy dataset of 400 reports was created for demonstration purposes. SPD utilizes 1.6+ million incident/offense reports for training and validation. Note that the small size of the example data creates different considerations for data decisions, computational cost, algorithm selection and tuning, etc. A more detailed description of the dataset, as well as SPD's data engineering practices are included in 'feature_engineering_training_documentation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1bd736c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dummy dataset\n",
    "biasdf = pd.read_csv('dummy_narrative_github.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e01bb",
   "metadata": {},
   "source": [
    "The 'train_report_ids' and 'test_report_ids' files contain the report_ids of reports that have gone through the feature engineering process in past runs. report_ids of reports processed in this run are appended at the end of this notebook to the same files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47053b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read report_ids that have already been processed\n",
    "reports_train = pd.read_csv('train_report_ids.csv', header= None)\n",
    "reports_train_list = set(reports_train[0].values)\n",
    "reports_test = pd.read_csv('test_report_ids.csv', header= None)\n",
    "reports_test_list = set(reports_test[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e33836aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create combined list of report ids to filter out in case they appear in the biasdf data source\n",
    "reports_list = reports_test_list | reports_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e672fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataset for report_ids not in reports_list (already processed)\n",
    "biasdf = biasdf[~biasdf['report_id'].isin(reports_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb3ae7",
   "metadata": {},
   "source": [
    "Reports in draft/pending/rejected status are not read as they might be modified in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f84b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only reports that are marked as completed\n",
    "biasdf = biasdf[(biasdf['approval_status'] != 'Draft') & (biasdf['approval_status'] != 'Pending Approval') & (biasdf['approval_status'] != 'Rejected')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b06da4",
   "metadata": {},
   "source": [
    "### Feedback Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886f6a3",
   "metadata": {},
   "source": [
    "In this step, the user reads their version of completed tasks (i.e., a file with the IDs of reports that have been flagged by the classifier and already adjusted as needed by the Bias Crime Unit). At SPD, we read the RMS tasks table and api_log to correctly categorize reports with bias events that have been associated to 'New Bias Crime Confirmation' tasks. Please see the documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a42bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that completed_tasks.csv exists (if it's the first time running the classifier):\n",
    "if os.path.isfile('completed_tasks.csv'):\n",
    "    \n",
    "    #read completed_tasks table\n",
    "    completed_tasks = pd.read_csv(\"completed_tasks.csv\")\n",
    "    \n",
    "else:\n",
    "    # if no completed tasks file, continue code\n",
    "    print('no completed tasks.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eae6c2",
   "metadata": {},
   "source": [
    "Read the offenses table (i.e., a table with the indicator used to label reports associated with tasks) with the 'is_suspected_hate_crime' flag to label reports that were confirmed as events with bias elements by the bias crime unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eabef4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in offenses table to get 'is_suspected_hate_crime' field\n",
    "label_df = pd.read_csv(\"offenses.csv\")\n",
    "\n",
    "#keep only positive class\n",
    "positive_ren = label_df[label_df['is_suspected_hate_crime'] == 1]\n",
    "\n",
    "#join positive rens to completed_tasks to get label (if completed task not in positive list, then it's negative)\n",
    "positive_label = pd.merge(positive_ren, completed_tasks, on=['reporting_event_number'], how='inner')\n",
    "positive_label.rename(columns= {'is_suspected_hate_crime':'actual_label'}, inplace=True)\n",
    "\n",
    "#create list of reporting event numbers from completed tasks that are positive\n",
    "list_positive_tasks = set(positive_label['reporting_event_number'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2c917",
   "metadata": {},
   "source": [
    "## 2. Label Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d3bbf",
   "metadata": {},
   "source": [
    "To label reports for training, we use reports with offenses associated to incidents with bias elements, crimes with bias elements, and hate crimes. We also use output from previous tasks to label reports that were true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66b37599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Label\n",
    "\n",
    "def label_function(df):\n",
    "    \n",
    "    if df['reporting_event_number'] in list_positive_tasks:\n",
    "        return 1\n",
    "    \n",
    "    elif df['crime_description_1'] in ['Incident Contains Bias Elements -- NO CRIME', 'Offense Contains Bias Elements -- CRIME',\n",
    "                                     'RCW - 9A.36.080 | HATE CRIME OFFENSE', 'SMC - - 12A.06.115 | MALICIOUS HARASSMENT',\n",
    "                                     'X91 | MALICIOUS HARASSMENT', 'X92 | BIAS INCIDENT', 'RCW - 9A.36.080 | MALICIOUS HARASSMENT']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function and create a new column\n",
    "biasdf['label'] = biasdf.apply(label_function, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ab553",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "448763c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure date field has date format\n",
    "biasdf['event_start_date'] = biasdf['event_start_date'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7641a4",
   "metadata": {},
   "source": [
    "If some reports don't have narratives, we still want to use them if they have demographic information about the victim(s)/suspects(s). With this purpose, we fill missing narratives with a neutral word for preprocessing. This is a methodological decision based on the assumption that the word of choice is not more likely to be associated with the positive or negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "630497c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty narratives with neutral word\n",
    "biasdf['narrative'] = biasdf['narrative'].fillna('narrative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06ee724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the pre-processing functions to the 'narrative' column\n",
    "bias_df_nlp = biasdf.copy()\n",
    "bias_df_nlp['corpus'] = bias_df_nlp['narrative'].apply(removeStopWords)\n",
    "bias_df_nlp['corpus'] = bias_df_nlp['corpus'].apply(removeFeatures)\n",
    "bias_df_nlp['corpus'] = bias_df_nlp['corpus'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bbee69",
   "metadata": {},
   "source": [
    "## 4.  One-Hot Encoding Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f4542",
   "metadata": {},
   "source": [
    "The next step is to create categorical variables (i.e., dummies) for demographic fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5fe04357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If after preprocessing the narrative is still blank, replace with neutral word:\n",
    "bias_df_nlp['corpus'] = bias_df_nlp['corpus'].replace('','narrative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b6bf056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the jurisdiction uses special characters for 'missing' fields, make them consistent:\n",
    "\n",
    "df = bias_df_nlp.copy()\n",
    "\n",
    "#in our dataset unknown ages are inputted as -1\n",
    "df['subject_age_1'] = df['subject_age_1'].replace(-1, np.NaN)\n",
    "df['victim_age_1'] = df['victim_age_1'].replace(-1, np.NaN)\n",
    "\n",
    "df['subject_race_1'] = df['subject_race_1'].replace('-', 'Sub_Race_Unknown')\n",
    "df['subject_race_1'] = df['subject_race_1'].fillna('Sub_Race_Unknown')\n",
    "df['subject_race_1'] = df['subject_race_1'].replace('Unknown', 'Sub_Race_Unknown')\n",
    "\n",
    "df['victim_race_1'] = df['victim_race_1'].replace('-', 'Vic_Race_Unknown')\n",
    "df['victim_race_1'] = df['victim_race_1'].fillna('Vic_Race_Unknown')\n",
    "df['victim_race_1'] = df['victim_race_1'].replace('Unknown', 'Vic_Race_Unknown')\n",
    "\n",
    "df['subject_gender_1'] = df['subject_gender_1'].replace('-', 'Sub_Gender_Unknown')\n",
    "df['subject_gender_1'] = df['subject_gender_1'].fillna('Sub_Gender_Unknown')\n",
    "df['subject_gender_1'] = df['subject_gender_1'].replace('Unknown', 'Sub_Gender_Unknown')\n",
    "\n",
    "df['victim_gender_1'] = df['victim_gender_1'].replace('-', 'Vic_Gender_Unknown')\n",
    "df['victim_gender_1'] = df['victim_gender_1'].fillna('Vic_Gender_Unknown')\n",
    "df['victim_gender_1'] = df['victim_gender_1'].replace('Unknown', 'Vic_Gender_Unknown')\n",
    "\n",
    "df['subject_ethnicity_1'] = df['subject_ethnicity_1'].replace('-', 'Sub_Ethni_Unknown')\n",
    "df['subject_ethnicity_1'] = df['subject_ethnicity_1'].fillna('Sub_Ethni_Unknown')\n",
    "df['subject_ethnicity_1'] = df['subject_ethnicity_1'].replace('Unknown', 'Sub_Ethni_Unknown')\n",
    "\n",
    "df['victim_ethnicity_1'] = df['victim_ethnicity_1'].replace('-', 'Vic_Ethni_Unknown')\n",
    "df['victim_ethnicity_1'] = df['victim_ethnicity_1'].fillna('Vic_Ethni_Unknown')\n",
    "df['victim_ethnicity_1'] = df['victim_ethnicity_1'].replace('Unknown', 'Vic_Ethni_Unknown')\n",
    "\n",
    "df['beat'] = df['beat'].replace('99', 'beat_Unknown')\n",
    "df['beat'] = df['beat'].replace('-', 'beat_Unknown')\n",
    "df['beat'] = df['beat'].replace('OOJ', 'beat_OOJ')\n",
    "df['beat'] = df['beat'].replace('Unknown', 'beat_Unknown')\n",
    "df['beat'] = df['beat'].fillna('beat_Unknown')\n",
    "\n",
    "df['precinct'] = df['precinct'].replace('Unknown', 'precinct_Unknown')\n",
    "df['precinct'] = df['precinct'].replace('-', 'precinct_Unknown')\n",
    "df['precinct'] = df['precinct'].replace('OOJ', 'precinct_OOJ')\n",
    "df['precinct'] = df['precinct'].fillna('precinct_Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3927395",
   "metadata": {},
   "source": [
    "We use Scikit-learn's OneHotEncoder to create dummies per unique category for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9243ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "285a50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummies\n",
    "\n",
    "precinct_e = ohe.fit_transform(df[['precinct']])\n",
    "new_column_names = [category for category in ohe.categories_[0]]\n",
    "precinct_df = pd.DataFrame(precinct_e.toarray(), columns=new_column_names)\n",
    "df = pd.concat([df, precinct_df], axis=1)\n",
    "\n",
    "gender_e = ohe.fit_transform(df[['victim_gender_1']])\n",
    "new_column_names = [category for category in ohe.categories_[0]]\n",
    "gender_df = pd.DataFrame(gender_e.toarray(), columns=new_column_names)\n",
    "df = pd.concat([df, gender_df], axis=1)\n",
    "\n",
    "race_e = ohe.fit_transform(df[['victim_race_1']])\n",
    "new_column_names = [category for category in ohe.categories_[0]]\n",
    "race_df = pd.DataFrame(race_e.toarray(), columns=new_column_names)\n",
    "df = pd.concat([df, race_df], axis=1)\n",
    "\n",
    "ethnicity_e = ohe.fit_transform(df[['victim_ethnicity_1']])\n",
    "new_column_names = [category for category in ohe.categories_[0]]\n",
    "ethnicity_df = pd.DataFrame(ethnicity_e.toarray(), columns=new_column_names)\n",
    "df = pd.concat([df, ethnicity_df], axis=1)\n",
    "\n",
    "beat_e = ohe.fit_transform(df[['beat']])\n",
    "new_column_names = [category for category in ohe.categories_[0]]\n",
    "beat_df = pd.DataFrame(beat_e.toarray(), columns=new_column_names)\n",
    "df = pd.concat([df, beat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4afdae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of OneHotEncoder for Subject's categories\n",
    "ohe_subject = OneHotEncoder()\n",
    "subject_race_e = ohe_subject.fit_transform(df[['subject_race_1']])\n",
    "\n",
    "# Rename the one-hot encoded columns with a prefix to differentiate them\n",
    "new_column_names = ['subject_' + category for category in ohe_subject.categories_[0]]\n",
    "\n",
    "\n",
    "subject_race_df = pd.DataFrame(subject_race_e.toarray(), columns=new_column_names)\n",
    "df = pd.concat([df, subject_race_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd80857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_gender_e = ohe_subject.fit_transform(df[['subject_gender_1']])\n",
    "new_column_names = ['subject_' + category for category in ohe_subject.categories_[0]]\n",
    "\n",
    "subject_gender_df = pd.DataFrame(subject_gender_e.toarray(), columns=new_column_names)\n",
    "\n",
    "df = pd.concat([df, subject_gender_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c22b5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ethnicity_e = ohe_subject.fit_transform(df[['subject_ethnicity_1']])\n",
    "new_column_names = ['subject_' + category for category in ohe_subject.categories_[0]]\n",
    "\n",
    "subject_ethnicity_df = pd.DataFrame(subject_ethnicity_e.toarray(), columns=new_column_names)\n",
    "\n",
    "df = pd.concat([df, subject_ethnicity_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884edb6",
   "metadata": {},
   "source": [
    "Sometimes the new data might not include all possible values (e.g., no event with a Native Hawaiian or Other Pacific Islander victim occurred in that month); as such, we need to make sure all possible values are represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "56d2b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK IF COLUMN IN LIST IS PRESENT, IF NOT, CREATE AND ASSIGN 0 TO IT\n",
    "\n",
    "columns = ['victim_age_1','subject_age_1','East', 'North', 'precinct_OOJ', 'South', 'Southwest', 'West', 'precinct_Unknown', 'Female',\n",
    " 'Gender Diverse (gender non-conforming and/or transgender)', 'Male', 'Vic_Gender_Unknown',\n",
    " 'American Indian or Alaska Native', 'Asian', 'Black or African American', 'Native Hawaiian or Other Pacific Islander',\n",
    " 'Vic_Race_Unknown', 'White', 'Hispanic Or Latino', 'Not Hispanic Or Latino', 'Vic_Ethni_Unknown',\n",
    " 'subject_American Indian or Alaska Native', 'subject_Asian', 'subject_Black or African American',\n",
    " 'subject_Native Hawaiian or Other Pacific Islander', 'subject_Sub_Race_Unknown', 'subject_White',\n",
    " 'subject_Female', 'subject_Gender Diverse (gender non-conforming and/or transgender)',\n",
    " 'subject_Male', 'subject_Sub_Gender_Unknown', 'subject_Hispanic Or Latino', 'subject_Not Hispanic Or Latino',\n",
    " 'subject_Sub_Ethni_Unknown', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3', 'D1', 'D2', 'D3', 'E1', 'E2', 'E3', 'F1', 'F2',\n",
    " 'F3', 'G1', 'G2', 'G3', 'H1', 'H2', 'H3', 'J1', 'J2', 'J3', 'K1', 'K2', 'K3', 'L1', 'L2', 'L3', 'M1', 'M2', 'M3',\n",
    " 'N1', 'N2', 'N3', 'O1', 'O2', 'O3', 'Q1', 'Q2', 'Q3', 'R1', 'R2', 'R3', 'S1', 'S2', 'S3', 'U1', 'U2', 'U3',\n",
    " 'beat_Unknown', 'W1', 'W2', 'W3', 'beat_OOJ']\n",
    "\n",
    "for column in columns:\n",
    "    if column not in df.columns:\n",
    "        df[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed701bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE FINAL FEATURES (remove original categorical variables, leave dummies)\n",
    "\n",
    "final_features = df[['label','report_id', 'reporting_event_number', 'event_start_date','victim_age_1', \n",
    " 'subject_age_1','corpus', 'East', 'North', 'precinct_OOJ', 'South', 'Southwest', 'West', 'precinct_Unknown', 'Female',\n",
    " 'Gender Diverse (gender non-conforming and/or transgender)', 'Male', 'Vic_Gender_Unknown',\n",
    " 'American Indian or Alaska Native', 'Asian', 'Black or African American', 'Native Hawaiian or Other Pacific Islander',\n",
    " 'Vic_Race_Unknown', 'White', 'Hispanic Or Latino', 'Not Hispanic Or Latino', 'Vic_Ethni_Unknown',\n",
    " 'subject_American Indian or Alaska Native', 'subject_Asian', 'subject_Black or African American',\n",
    " 'subject_Native Hawaiian or Other Pacific Islander', 'subject_Sub_Race_Unknown', 'subject_White',\n",
    " 'subject_Female', 'subject_Gender Diverse (gender non-conforming and/or transgender)',\n",
    " 'subject_Male', 'subject_Sub_Gender_Unknown', 'subject_Hispanic Or Latino', 'subject_Not Hispanic Or Latino',\n",
    " 'subject_Sub_Ethni_Unknown', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3', 'D1', 'D2', 'D3', 'E1', 'E2', 'E3', 'F1', 'F2',\n",
    " 'F3', 'G1', 'G2', 'G3', 'H1', 'H2', 'H3', 'J1', 'J2', 'J3', 'K1', 'K2', 'K3', 'L1', 'L2', 'L3', 'M1', 'M2', 'M3',\n",
    " 'N1', 'N2', 'N3', 'O1', 'O2', 'O3', 'Q1', 'Q2', 'Q3', 'R1', 'R2', 'R3', 'S1', 'S2', 'S3', 'U1', 'U2', 'U3',\n",
    " 'beat_Unknown', 'W1', 'W2', 'W3', 'beat_OOJ']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b3fdf",
   "metadata": {},
   "source": [
    "## 5. Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07dc9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "biasdf = final_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a131efb9",
   "metadata": {},
   "source": [
    "We perform a 80/20 split between training and validation data, but with larger datasets a smaller portion of the data can be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a007d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split on index\n",
    "train, test = train_test_split(biasdf.index, test_size=0.2, random_state=0)\n",
    "X_train, y_train = biasdf.loc[train, 'corpus'],  biasdf.loc[train, 'label']\n",
    "X_test, y_test = biasdf.loc[test, 'corpus'],  biasdf.loc[test, 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186bbfce",
   "metadata": {},
   "source": [
    "We train the vectorizer only on the training data to avoid data leakage. For the sake of the example, we only extract 50 features from the data. At SPD, we extract 3,000 text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "541c3ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer fitted only to training set\n",
    " \n",
    "#The max_features parameter tells the vectorizer to only consider the 50 most frequent words from the text corpus. \n",
    "cv = CountVectorizer(max_features=50)\n",
    "\n",
    "cv.fit(X_train)\n",
    "X_train = cv.transform(X_train)\n",
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7d5445d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['countvectorizer.pkl']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save trained vectorizer for feature engineering\n",
    "joblib.dump(cv, 'countvectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e722116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get word vectors from vectorizer for column renaming\n",
    "words = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4d85f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to avoid error with hstack make numeric columns numeric type\n",
    "biasdf_add = biasdf.drop(columns=['report_id', 'event_start_date', 'reporting_event_number',\n",
    "                                               'label', 'corpus'], axis=1).apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27c98fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge sparse matrix back with other features\n",
    "X_train = hstack([X_train, biasdf_add.loc[train].values])\n",
    "\n",
    "X_test = hstack([X_test, biasdf_add.loc[test].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8d380",
   "metadata": {},
   "source": [
    "### Save dataframes for training/tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ed34365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get report_ids to update processed report ids CSV file (keep track of which reports have been processed)\n",
    "X_train_report_id = biasdf.loc[train][['report_id']]\n",
    "X_test_report_id = biasdf.loc[test][['report_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c9e772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the ids of the processed reports to the report_ids CSV file if it exists\n",
    "X_train_report_id.to_csv('train_report_ids.csv', mode='a', header=False, index=False)\n",
    "X_test_report_id.to_csv('test_report_ids.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4db391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to dense\n",
    "X_train_df = pd.DataFrame.sparse.from_spmatrix(X_train)\n",
    "X_test_df = pd.DataFrame.sparse.from_spmatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1df01afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y arrays to DF\n",
    "y_train_df = pd.DataFrame(y_train).reset_index(drop=True)\n",
    "y_train_df = y_train_df.rename(columns={0: \"label\"})\n",
    "y_test_df = pd.DataFrame(y_test).reset_index(drop=True)\n",
    "y_test_df = y_test_df.rename(columns={0: \"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d5c1b4",
   "metadata": {},
   "source": [
    "You should end up with 141 features: 91 dummies for demographic values and 50 text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ce8dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316, 1)\n",
      "(316, 141)\n",
      "(79, 1)\n",
      "(79, 141)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_df.shape)\n",
    "print(X_train_df.shape)\n",
    "print(y_test_df.shape)\n",
    "print(X_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fd371b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine labels and features\n",
    "X_train_df['label'] = y_train_df['label']\n",
    "X_test_df['label'] = y_test_df['label']\n",
    "train_df = X_train_df\n",
    "test_df = X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8fbfcae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['label'].astype(int)\n",
    "test_df['label'] = test_df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2318e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder so first column is label since XGBoost (Amazon's implementation) reads the first column as the label\n",
    "train_cols = train_df.columns.tolist()\n",
    "train_cols = train_cols[-1:] + train_cols[:-1]\n",
    "train_df = train_df[train_cols]\n",
    "\n",
    "test_cols = test_df.columns.tolist()\n",
    "test_cols = test_cols[-1:] + test_cols[:-1]\n",
    "test_df = test_df[test_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21c6e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can rename the columns using the words from the vectorizer\n",
    "\n",
    "names = ['victim_age_1','subject_age_1','East', 'North', 'precinct_OOJ', 'South', 'Southwest', 'West', 'precinct_Unknown',\n",
    " 'Female','Gender Diverse (gender non-conforming and/or transgender)', 'Male', 'Vic_Gender_Unknown',\n",
    " 'American Indian or Alaska Native', 'Asian', 'Black or African American', 'Native Hawaiian or Other Pacific Islander',\n",
    " 'Vic_Race_Unknown', 'White', 'Hispanic Or Latino', 'Not Hispanic Or Latino', 'Vic_Ethni_Unknown',\n",
    " 'subject_American Indian or Alaska Native', 'subject_Asian', 'subject_Black or African American',\n",
    " 'subject_Native Hawaiian or Other Pacific Islander', 'subject_Sub_Race_Unknown', 'subject_White',\n",
    " 'subject_Female', 'subject_Gender Diverse (gender non-conforming and/or transgender)',\n",
    " 'subject_Male', 'subject_Sub_Gender_Unknown', 'subject_Hispanic Or Latino', 'subject_Not Hispanic Or Latino',\n",
    " 'subject_Sub_Ethni_Unknown', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3', 'D1', 'D2', 'D3', 'E1', 'E2', 'E3', 'F1', 'F2',\n",
    " 'F3', 'G1', 'G2', 'G3', 'H1', 'H2', 'H3', 'J1', 'J2', 'J3', 'K1', 'K2', 'K3', 'L1', 'L2', 'L3', 'M1', 'M2', 'M3',\n",
    " 'N1', 'N2', 'N3', 'O1', 'O2', 'O3', 'Q1', 'Q2', 'Q3', 'R1', 'R2', 'R3', 'S1', 'S2', 'S3', 'U1', 'U2', 'U3',\n",
    " 'beat_Unknown', 'W1', 'W2', 'W3', 'beat_OOJ']\n",
    "\n",
    "col_names = np.concatenate((['label'], words, names))\n",
    "\n",
    "train_df = train_df.rename(columns=dict(zip(train_df.columns, col_names), inplace=True))\n",
    "test_df = test_df.rename(columns=dict(zip(test_df.columns, col_names), inplace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829a140",
   "metadata": {},
   "source": [
    "We save the files without headers since the AWS XGBoost model object takes csv files with no column name.\n",
    "If not running for the first time, we append new processed reports to the training and testing datasets (i.e., we train on all the reports ever processed every month). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eb33d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append new processed reports to training and testing file for xgboost\n",
    "\n",
    "# Append the DataFrame to the CSV file\n",
    "train_df.to_csv('train_final.csv', mode='a', header=False, index=False)\n",
    "test_df.to_csv('test_final.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c267d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if needed, save with headers:\n",
    "\n",
    "def save_dataframe(df, filename):\n",
    "    if os.path.isfile(filename):\n",
    "        df.to_csv(filename, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(filename, index=False)\n",
    "            \n",
    "# Save train and test dataframes\n",
    "save_dataframe(train_df, 'train_final_wh.csv')\n",
    "save_dataframe(test_df, 'test_final_wh.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
