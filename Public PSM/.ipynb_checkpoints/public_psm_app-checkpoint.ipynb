{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118fa2d0",
   "metadata": {},
   "source": [
    "This file uses imported functions from the public_acn_psm file. The functions file contains all of the functions required for this file to properly run.\n",
    "\n",
    "The code uses the following packages: \n",
    "- pandas\n",
    "- datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install xgboost imported in public_acn_psm\n",
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb80642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages/functions\n",
    "import public_acn_psm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2086ba62",
   "metadata": {},
   "source": [
    "The following code reads the csv file, model_features.csv, that was the result of the code from the file public_psm_feature_engineering.\n",
    "\n",
    "Unnecessary columns are dropped. In addition, columns \"Officer ID\" and \"Officer Squad\" are converted to type 'str' to prevent errors. The rows where the column \"Precinct\" value is equal to 'OOJ' are dropped as it caused problems with the model.\n",
    "\n",
    "An important note in this code is that the dataframe created from model_features.csv is cut so that it only consists of the first 6000 rows. This allows for the model to take a much smaller amount of time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb66461",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create dataframe from model_features.csv\n",
    "df_orig = pd.read_csv(\"model_features_sunny_test.csv\")\n",
    "df_output_all = pd.DataFrame(data = df_orig)\n",
    "df_output_all = df_output_all.drop('Unnamed: 0', axis = 1)\n",
    "df_output_all['Officer ID'] = df_output_all['Officer ID'].astype(str)\n",
    "df_output_all['Officer Squad'] = df_output_all['Officer Squad'].astype(str)\n",
    "df_output_all = df_output_all[df_output_all['Precinct'] != 'OOJ']\n",
    "# decrease dataset size to decrease runtime\n",
    "df_output_all = df_output_all[:6000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da1e009",
   "metadata": {},
   "source": [
    "The code below creates a list of dataframes in which each dataframe contains a unique combination of the following columns:\n",
    "- \"Precinct\"\n",
    "- \"observation_year_d\"\n",
    "- \"observation_month_d\"\n",
    "\n",
    "Essentially, each row within a dataframe would contain the same values for those three columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac02929",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dfs = [group for i, group in df_output_all.groupby(['Precinct','observation_year_d','observation_month_d'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0830f0",
   "metadata": {},
   "source": [
    "This block of code has many parts:\n",
    "- Creates a for-loop that iterates through each dataframe in unique_dfs.\n",
    "- Creates another for-loop within the first for-loop in which it assigns the values of the following variables: \n",
    "    - precinct\n",
    "    - year\n",
    "    - month\n",
    "- Runs the psm model using the function **evaluate_all_stops** and dataframe 'df'. The model returns the following:\n",
    "    - eval_flag\n",
    "    - summaries\n",
    "    - propensities\n",
    "- If the sample size is large enough, the columns of dataframe 'propensities' is filtered, renamed, and added to the combined propensities dataframe. In addition, the dataframe 'summaries' is added to the combined summaries dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e50dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedSummaries = pd.DataFrame()\n",
    "combinedPropensities = pd.DataFrame()\n",
    "for df_all in unique_dfs:\n",
    "    df = df_all\n",
    "    for index, row in df_all.iterrows():  \n",
    "        precinct = df_all['Precinct']\n",
    "        year = df_all['observation_year_d']\n",
    "        month = df_all['observation_month_d']\n",
    "        df['precinct'] = precinct\n",
    "        df['observation_year_d'] = year\n",
    "        df['observation_month_d'] = month\n",
    "    print(f'read features data frame for precinct: {precinct}, month: {year}-{month}', df.shape)\n",
    "    # run psm model\n",
    "    eval_flag, summaries, propensities = public_acn_psm.evaluate_all_stops(df)\n",
    "    if eval_flag:\n",
    "        # filter columns \n",
    "        propensities = propensities[\n",
    "            [\n",
    "                'watch_d', 'Precinct_watch_d', 'observation_datetime_d', 'observation_day_d', 'observation_week_d', 'observation_week_of_month_d',\n",
    "                'Officer Race', 'Subject Perceived Race', 'label', \n",
    "                'prediction', 'probability_0', 'probability_1', 'weight', 'mean_control', \n",
    "                'mean_treat', 'mean_control_sum', 'mean_treat_sum', 'absolute_difference', \n",
    "                'run_timestamp', 'Frisk Flag', 'Subject Age Group', 'Subject Perceived Race'\n",
    "            ]\n",
    "        ] \n",
    "\n",
    "        # rename prediction set of columns\n",
    "        propensities = propensities.rename(columns = {\n",
    "            'label': 'subject_race_label_d',\n",
    "            'prediction': 'subject_race_label_pred',\n",
    "            'probability_0': 'probability_0_pred',\n",
    "            'probability_1': 'probability_1_pred',\n",
    "            'weight': 'weight_pred',\n",
    "            'mean_control': 'mean_control_pred',\n",
    "            'mean_treat': 'mean_treat_pred',\n",
    "            'mean_control_sum': 'mean_control_sum_pred',\n",
    "            'mean_treat_sum': 'mean_treat_sum_pred',\n",
    "            'absolute_difference': 'disparity_pred'\n",
    "        })\n",
    "        print('evaluation complete')\n",
    "        combinedSummaries = pd.concat([combinedSummaries, summaries])\n",
    "        combinedPropensities = pd.concat([combinedPropensities, propensities])\n",
    "    else:\n",
    "        print(f'disparity not evaluated due to small sample size', df.shape[0])\n",
    "        response_code = 2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba552219",
   "metadata": {},
   "source": [
    "The index for both resulting dataframes are reset. Then, both are exported to their respective csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedSummaries = combinedSummaries.reset_index(drop = True)\n",
    "combinedPropensities = combinedPropensities.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedSummaries.to_csv('summaries_results.csv', index = False)\n",
    "combinedPropensities.to_csv('propensities_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297c8b0",
   "metadata": {},
   "source": [
    "The two resulting dataframes can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fdbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedSummaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedPropensities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
